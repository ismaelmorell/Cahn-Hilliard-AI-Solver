{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**0. Importing packages**"
      ],
      "metadata": {
        "id": "u9g5Fmklg43T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import pickle\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from scipy.fft import fft2, ifft2, fftfreq"
      ],
      "metadata": {
        "id": "glI849G-gB7T"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Generating datasets**\n"
      ],
      "metadata": {
        "id": "9a_QYXaVfROB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = 10 #domain length\n",
        "N = 100 #number of grid points per dimension\n",
        "delta_x = L / N\n",
        "delta_y = L / N\n",
        "delta_t = 0.000001\n",
        "iterations = 2000 #number of timesteps per data example\n",
        "\n",
        "num_datasets = 5\n",
        "num_datapoints = 1000 # num datapoints per dataset\n",
        "sequence_length = 10 # num snapshots per datapoint\n",
        "\n",
        "frequencies = fftfreq(N, d=1/N) #frequencies used in scipy fft\n",
        "k1 = np.tile(frequencies,(N,1)) #frequencies associated to x variable in fourier series\n",
        "k2 = k1.T #frequencies associated to y variable in fourier series\n",
        "spectral_laplace = - (2*np.pi*(1 / L))**2 * (k1**2 + k2**2) #helps calculate laplacian applied to\n",
        "                                                            #fourier coefficients\n"
      ],
      "metadata": {
        "id": "YpDy4b2dfYwy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate datasets and save them\n",
        "for k in range(num_datasets):\n",
        "    dataset = []\n",
        "    for i in range(num_datapoints):\n",
        "        if i%10 == 0:\n",
        "            print(f'Generating data point {i}')\n",
        "        #Generate random parameters and initial conditions\n",
        "        D = random.uniform(1.0, 10.0)\n",
        "        l = random.uniform(1.0, 10.0)\n",
        "        c = np.random.uniform(-0.01, 0.01, (N, N))\n",
        "\n",
        "        #Generate data\n",
        "        current_simulation = []\n",
        "        for j in range(iterations):\n",
        "            #We only add sequence_length number of snapshots to current_simulation\n",
        "            if j%(iterations / sequence_length) == 0:\n",
        "                current_simulation.append(c)\n",
        "            #Compute c at next time step\n",
        "            numerator = fft2(c) + delta_t*D*spectral_laplace*fft2(c**3-c)\n",
        "            denominator = 1+delta_t*D*l*spectral_laplace*spectral_laplace\n",
        "            c = ifft2( numerator / denominator ).real\n",
        "\n",
        "        #Add new data to dataset\n",
        "        dataset.append({'D': D, 'l': l, 'data': current_simulation})\n",
        "\n",
        "    print(f'Done generating dataset {k+1}')\n",
        "    file_path = f'ch_video_dataset_{k+1}.pkl'\n",
        "\n",
        "    with open(file_path, \"wb\") as file:\n",
        "        pickle.dump(dataset, file)\n",
        "    print(f'Done with dataset {k+1}!')"
      ],
      "metadata": {
        "id": "Yni0fEh5faQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Loading and Preprocessing datasets**"
      ],
      "metadata": {
        "id": "9797EB5efkHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's load the dataset\n",
        "dataset = []\n",
        "for i in range(num_datasets):\n",
        "    with open(f'ch_video_dataset_{i+1}.pkl', 'rb') as f:\n",
        "        dataset = dataset + pickle.load(f)\n",
        "\n",
        "#Reshaping data into dimensions time_step x nChannels x Height x Width\n",
        "for i in range(len(dataset)):\n",
        "    dataset[i]['data'] = np.reshape(np.array(dataset[i]['data']), (sequence_length,1,N,N))\n",
        "\n",
        "#Calculating mean and std deviation for z-score normalization\n",
        "sum = 0\n",
        "for i in range(len(dataset)):\n",
        "    sum += np.sum(dataset[i]['data'])\n",
        "mean = sum / (len(dataset) * sequence_length * N * N)\n",
        "\n",
        "sum = 0\n",
        "for i in range(len(dataset)):\n",
        "    sum += np.sum((dataset[i]['data'] - mean)**2)\n",
        "sigma = np.sqrt(sum / (len(dataset) * sequence_length * N * N))"
      ],
      "metadata": {
        "id": "ntbupbxmfv0Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining dataset class and dataloader objects\n",
        "class MyCustomDataset(Dataset):\n",
        "    def __init__(self, original_dataset, transform=None):\n",
        "        self.original_dataset = original_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of samples\n",
        "        return len(self.original_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get one sample from the original dataset\n",
        "        sample = self.original_dataset[idx]\n",
        "\n",
        "        # Extract the video data and label data\n",
        "        video_data = sample['data'] # This should be a NumPy array or PIL Image\n",
        "        label_data = torch.tensor([sample['D'], sample['l']]).float()\n",
        "\n",
        "        # Apply transformations to the video (if necessary)\n",
        "        if self.transform:\n",
        "            video_data = self.transform(video_data)\n",
        "\n",
        "        return video_data, label_data\n",
        "\n",
        "\n",
        "def pre_process(video):\n",
        "    video = torch.from_numpy(video)\n",
        "    return ((video - mean) / sigma).float()\n",
        "\n",
        "train_data = MyCustomDataset(dataset[100:5000], pre_process)\n",
        "cv_data = MyCustomDataset(dataset[0:100], pre_process)\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "cv_loader = DataLoader(cv_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "WSi-uNCiitLJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Defining training and evaluation functions**"
      ],
      "metadata": {
        "id": "SBEqPcQMjvqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation function\n",
        "def evaluate_model(model, val_loader, loss_function, device):\n",
        "    #Evaluates the model on the validation dataset.\n",
        "    #Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    running_val_loss = 0.0\n",
        "\n",
        "    #Disable gradient calculations\n",
        "    #We don't need to calculate gradients for validation, which saves memory and computation.\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            # Move data to the specified device\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = loss_function(outputs, labels)\n",
        "\n",
        "            # Accumulate the loss\n",
        "            # .item() gets the raw Python number from the tensor\n",
        "            # inputs.size(0) is the batch size\n",
        "            running_val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    #Calculate the average loss over the entire validation set\n",
        "    average_val_loss = running_val_loss / len(val_loader.dataset)\n",
        "\n",
        "    return average_val_loss"
      ],
      "metadata": {
        "id": "C5WM9gTMj7bp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training loop\n",
        "def training_loop(model, train_loader, cv_loader, criterion, optimizer, scheduler, device,\n",
        "                  num_epochs=50, patience=10):\n",
        "\n",
        "  #Early stopping parameters\n",
        "  epochs_no_improve = 0\n",
        "  min_val_loss = float('inf')\n",
        "  best_model_state = None\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      model.train()\n",
        "      running_train_loss = 0\n",
        "      for feature_batch, label_batch in train_loader:\n",
        "          #Move data to GPU\n",
        "          feature_batch = feature_batch.to(device)\n",
        "          label_batch = label_batch.to(device)\n",
        "\n",
        "          #Zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          #forward + backward + optimize\n",
        "          with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n",
        "            outputs = model(feature_batch)\n",
        "            loss= criterion(outputs, label_batch)\n",
        "\n",
        "          running_train_loss += loss.item() * feature_batch.size(0)\n",
        "\n",
        "          scaler.scale(loss).backward()\n",
        "          scaler.step(optimizer)\n",
        "\n",
        "          scaler.update()\n",
        "      #Print statistics\n",
        "      avg_train_loss = running_train_loss / len(train_loader.dataset)\n",
        "      avg_val_loss = evaluate_model(model, cv_loader, criterion, device)\n",
        "      scheduler.step(avg_val_loss)\n",
        "      print(f'Epoch: {epoch}, Avg train loss: {avg_train_loss}, Avg val loss: {avg_val_loss}')\n",
        "\n",
        "      if avg_val_loss < min_val_loss:\n",
        "        min_val_loss = avg_val_loss\n",
        "        epochs_no_improve = 0\n",
        "        # Save the best model state\n",
        "        best_model_state = model.state_dict()\n",
        "\n",
        "      else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "      if epochs_no_improve == patience:\n",
        "        print(f'Early stopping triggered after {epoch+1} epochs!')\n",
        "        break\n",
        "  print(f'Finished training with min_val_loss of {min_val_loss}')\n",
        "\n",
        "  return best_model_state"
      ],
      "metadata": {
        "id": "7jP2M3rHk9tH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Setting up model and hyperparameters for training**"
      ],
      "metadata": {
        "id": "VHvojxU-lMuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining Convolutional RNN class\n",
        "class ConvRNN(nn.Module):\n",
        "    def __init__(self, device=None):\n",
        "        super(ConvRNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding = 1)\n",
        "        self.fc1 = nn.Linear(32 * 25 * 25, 512)\n",
        "        self.rnn = nn.RNN(512, 512, num_layers=3, nonlinearity='relu', batch_first=True, device=device)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(512, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #Shape of input x is (batch_idx) x (time_step) x (nChannels) x (Height) x (Width)\n",
        "\n",
        "        #Convolutional step\n",
        "        b_size, t_size, c_size, h_size, w_size = x.shape\n",
        "        x = torch.reshape(x, (b_size * t_size, c_size, h_size, w_size))\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        x = x.view(b_size, t_size, -1)\n",
        "\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.dropout(out[:,-1,:])\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "2tlESETUld7k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's try using CUDA\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available and being used.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU.\")\n",
        "\n",
        "#Constructing Gradient Scaler\n",
        "scaler = GradScaler()\n",
        "\n",
        "#Constructing model\n",
        "model = ConvRNN(device)\n",
        "\n",
        "#Loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "#Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "\n",
        "#Set up lr scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=5)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6e9tTEiNnslL",
        "outputId": "465fdf72-b587-475c-bf6a-e18fcce91478"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available and being used.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3084056367.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvRNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=20000, out_features=512, bias=True)\n",
              "  (rnn): RNN(512, 512, num_layers=3, batch_first=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Train model and output best model state**"
      ],
      "metadata": {
        "id": "Sjb5moBPo1JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_model = training_loop(model, train_loader, cv_loader, criterion, optimizer, scheduler, device,\n",
        "                  num_epochs=50, patience=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ec0BYSElo7lN",
        "outputId": "ba50b128-8a80-43ea-a736-ccd3a7c3abd2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-852657703.py:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device.type == 'cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Avg train loss: 12.668449944087437, Avg val loss: 5.630335330963135\n",
            "Epoch: 1, Avg train loss: 5.32409631651275, Avg val loss: 4.814549922943115\n",
            "Epoch: 2, Avg train loss: 4.895151945620167, Avg val loss: 4.3019700050354\n",
            "Epoch: 3, Avg train loss: 4.758860840700111, Avg val loss: 4.6155924797058105\n",
            "Epoch: 4, Avg train loss: 4.739522348909962, Avg val loss: 4.228938579559326\n",
            "Epoch: 5, Avg train loss: 4.796003853934152, Avg val loss: 4.107840538024902\n",
            "Epoch: 6, Avg train loss: 4.584124496226408, Avg val loss: 5.097446918487549\n",
            "Epoch: 7, Avg train loss: 4.638980679803965, Avg val loss: 4.605401515960693\n",
            "Epoch: 8, Avg train loss: 4.591412334831394, Avg val loss: 4.129711627960205\n",
            "Epoch: 9, Avg train loss: 4.428692783822819, Avg val loss: 5.4402079582214355\n",
            "Epoch: 10, Avg train loss: 4.515507722971391, Avg val loss: 4.554859161376953\n",
            "Epoch: 11, Avg train loss: 4.683591982004594, Avg val loss: 4.094710826873779\n",
            "Epoch: 12, Avg train loss: 4.365301838310398, Avg val loss: 3.838188409805298\n",
            "Epoch: 13, Avg train loss: 4.422178157105738, Avg val loss: 3.818422794342041\n",
            "Epoch: 14, Avg train loss: 4.179660515687903, Avg val loss: 3.764040470123291\n",
            "Epoch: 15, Avg train loss: 4.097528096802381, Avg val loss: 3.988250970840454\n",
            "Epoch: 16, Avg train loss: 3.968426647575534, Avg val loss: 3.676522731781006\n",
            "Epoch: 17, Avg train loss: 3.9423657783196897, Avg val loss: 3.8744683265686035\n",
            "Epoch: 18, Avg train loss: 3.8852299768097547, Avg val loss: 3.645439386367798\n",
            "Epoch: 19, Avg train loss: 3.88620628551561, Avg val loss: 3.6319546699523926\n",
            "Epoch: 20, Avg train loss: 4.016522777323821, Avg val loss: 3.7213025093078613\n",
            "Epoch: 21, Avg train loss: 3.882898230260732, Avg val loss: 3.815419912338257\n",
            "Epoch: 22, Avg train loss: 3.9366102382114954, Avg val loss: 3.8290774822235107\n",
            "Epoch: 23, Avg train loss: 3.851131479691486, Avg val loss: 3.8184399604797363\n",
            "Epoch: 24, Avg train loss: 3.8582086471635466, Avg val loss: 3.890817165374756\n",
            "Epoch: 25, Avg train loss: 3.843890224962818, Avg val loss: 3.654323101043701\n",
            "Epoch: 26, Avg train loss: 3.743729328817251, Avg val loss: 3.6411449909210205\n",
            "Epoch: 27, Avg train loss: 3.7164895645453004, Avg val loss: 3.6318559646606445\n",
            "Epoch: 28, Avg train loss: 3.7328763689313615, Avg val loss: 3.6364316940307617\n",
            "Epoch: 29, Avg train loss: 3.72706303187779, Avg val loss: 3.7499961853027344\n",
            "Epoch: 30, Avg train loss: 3.7540071456286372, Avg val loss: 3.633945941925049\n",
            "Epoch: 31, Avg train loss: 3.696476553313586, Avg val loss: 3.639984369277954\n",
            "Epoch: 32, Avg train loss: 3.6790174003523224, Avg val loss: 3.639706611633301\n",
            "Epoch: 33, Avg train loss: 3.6871103146611426, Avg val loss: 3.6469438076019287\n",
            "Epoch: 34, Avg train loss: 3.6692020005595927, Avg val loss: 3.63683819770813\n",
            "Epoch: 35, Avg train loss: 3.664874517674349, Avg val loss: 3.6563198566436768\n",
            "Epoch: 36, Avg train loss: 3.671069946678317, Avg val loss: 3.648982524871826\n",
            "Epoch: 37, Avg train loss: 3.651422429960601, Avg val loss: 3.6344077587127686\n",
            "Epoch: 38, Avg train loss: 3.6561090735999904, Avg val loss: 3.646426200866699\n",
            "Epoch: 39, Avg train loss: 3.6700461878095356, Avg val loss: 3.6466689109802246\n",
            "Epoch: 40, Avg train loss: 3.664326812199184, Avg val loss: 3.644975423812866\n",
            "Epoch: 41, Avg train loss: 3.6584417132942044, Avg val loss: 3.639711856842041\n",
            "Epoch: 42, Avg train loss: 3.6618666335514614, Avg val loss: 3.642944812774658\n",
            "Epoch: 43, Avg train loss: 3.6564881815229144, Avg val loss: 3.652930736541748\n",
            "Epoch: 44, Avg train loss: 3.655643658151432, Avg val loss: 3.647944211959839\n",
            "Epoch: 45, Avg train loss: 3.652100448024516, Avg val loss: 3.646392345428467\n",
            "Epoch: 46, Avg train loss: 3.6571190359154526, Avg val loss: 3.6488311290740967\n",
            "Epoch: 47, Avg train loss: 3.6637485445762166, Avg val loss: 3.650840997695923\n",
            "Early stopping triggered after 48 epochs!\n",
            "Finished training with min_val_loss of 3.6318559646606445\n"
          ]
        }
      ]
    }
  ]
}